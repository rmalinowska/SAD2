{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ed4e8b",
   "metadata": {},
   "source": [
    "# Report for project 1 \n",
    "### Statistical Data Analysis 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db00ffb",
   "metadata": {},
   "source": [
    "#### Task 1 - data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad52f4b",
   "metadata": {},
   "source": [
    "a) \n",
    "Train set has 72208 observations and 5000 variables.\n",
    "\n",
    "Test set has 18052 observations and 5000 variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b94abc5",
   "metadata": {},
   "source": [
    "b) \n",
    "###### Raw data\n",
    "Firstly, let's look at the train raw data spanned by all possible values. We can see that there is a one huge bar close to zero and it doesn't allow to see anything else. So, let's look at the same data, but in the gene expression range from 0 to 10. Now we can see that there are may observations corresponding to other values than zero. All values are integers. For closer look we can skip the zero value.\n",
    "<div>\n",
    "<img src=\"plots/train_raw_full.png\" width=\"300\"/>\n",
    "<img src=\"plots/train_raw_0_10.png\" width=300\"/>\n",
    "<img src=\"plots/train_raw_05_10.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b4338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ab65653",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "040e4f22",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b547db",
   "metadata": {},
   "source": [
    "Now, the same thing for the test raw data. \n",
    "<div>\n",
    "<img src=\"plots/test_raw_full.png\" width=\"300\"/>\n",
    "<img src=\"plots/test_raw_0_10.png\" width=\"300\"/>\n",
    "<img src=\"plots/test_raw_05_10.png\" width=\"300\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a6a16",
   "metadata": {},
   "source": [
    "###### Preprocessed data\n",
    "As we've seen, raw data contains only gene expression values as integers. Here are the same plots, but for preprocessed data. First the training preprocessed data:\n",
    "\n",
    "<div>\n",
    "<img src=\"plots/train_pp_full.png\" width=\"300\"/>\n",
    "<img src=\"plots/train_pp_0_10.png\" width=\"300\"/>\n",
    "<img src=\"plots/train_pp_05_10.png\" width=\"300\"/>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fda3420",
   "metadata": {},
   "source": [
    "Now, test preprocessed data:\n",
    "<div>\n",
    "<img src=\"plots/test_pp_full.png\" width=\"300\"/>\n",
    "<img src=\"plots/test_pp_0_10.png\" width=\"300\"/>\n",
    "<img src=\"plots/test_pp_05_10.png\" width=\"300\"/>\n",
    "</div"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0274801",
   "metadata": {},
   "source": [
    "c) Let's sum up information about raw and preprocessed data by using some basic statistics.\n",
    "###### Summary of training raw data:\n",
    "Minimal value: 0 \\\n",
    "Maximal value: 35 451 \\\n",
    "Mean: 0.4421075 \\\n",
    "Median: 0.0 \\\n",
    "There are 328 811 428 zeros. \\\n",
    "There are 20 125 032 ones. \\\n",
    "There are 1 301 756 values greater than 10.  \n",
    "\n",
    "###### Summary of training preprocessed data:\n",
    "Minimal value: 0\\\n",
    "Maximal value: 21 078 940 \\\n",
    "Mean: 3.42741\\\n",
    "Median: 0.0\\\n",
    "There are 328 811 428 zeros\\\n",
    "There are 0 ones.\\\n",
    "There are 1 831 190 values greater than 10. \\\n",
    "\n",
    "###### Summary of test raw data:\n",
    "Minimal value: 0\\\n",
    "Maximal value: 35 451\\\n",
    "Mean: 0.44727832\\\n",
    "Median: 0.0\\\n",
    "There are 82 169 425 zeros.\\\n",
    "There are 5 039 252 ones.\\\n",
    "There are 330 617 values greater than 10.\n",
    "\n",
    "###### Summary of test preprocessed data:\n",
    "Minimal value: 0.0\\\n",
    "Maximal value: 21 078 940.0\\\n",
    "Mean: 3.657701\\\n",
    "Median: 0.0\\\n",
    "There are 82 169 425 zeros.\\\n",
    "There are 0 ones.\\\n",
    "There are 456 032 values greater than 10.\n",
    "\n",
    "\n",
    "\n",
    "While searching for common techiques that are applied on raw gene expression data I found out about normalization factor aka size factor. Dividing read counts from each sample by sample's size factor normalizes data throughout all samples by taking into account factors as sequencing depth and RNA composition.\n",
    "\n",
    "I checked if maybe out data was preprocessed in such manner, as we have a column with size factors in adata.obs and turns out it was!\n",
    "\n",
    "```python\n",
    "train_data = load_data(\"SAD2022Z_Project1_GEX_train.h5ad\")\n",
    "train_gex_size_factor = train_data.obs[\"GEX_size_factors\"].array\n",
    "train_raw_d = train_data.layers[\"counts\"].toarray()\n",
    "train_pp_guess = train_raw_d/train_gex_size_factor[:, None]\n",
    "train_pp_guess = train_pp_guess.reshape(train_pp_guess.shape[0]*train_pp_guess.shape[1],1)\n",
    "stats(train_pp_guess)\n",
    "```\n",
    "\n",
    "Basic statistics as above are the same for adata.X and for \"guessed\" normalization.\n",
    "\n",
    "[source](https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd08999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e51973e",
   "metadata": {},
   "source": [
    "d) \n",
    "###### Preprocessed\n",
    "Training preprocessed data without zeros in full range of values, in range from 0 to 20.\n",
    "<div>\n",
    "<img src=\"plots/train_pp_full_nozeros.png\" width=\"400\" />\n",
    "<img src=\"plots/train_pp_nozeros_0_20.png\" width=\"400\" />\n",
    "</div>\n",
    "Test preprocessed data without zeros in full range of values and in a range from 0 to 20:\n",
    "<div>\n",
    "<img src=\"plots/test_pp_full_nozeros.png\" width=\"400\" />\n",
    "<img src=\"plots/test_pp_nozeros_0_20.png\" width=\"400\" />\n",
    "</div>\n",
    "\n",
    "###### Raw\n",
    "Train raw data without zeros in full range of values and in a range from 0 to 20:\n",
    "<div>\n",
    "<img src=\"plots/train_raw_full_nozeros.png\" width=\"400\" />\n",
    "<img src=\"plots/train_raw_nozeros_0_20.png\" width=\"400\" />\n",
    "</div>\n",
    "Test raw data without zeros in full range of values and in range from 0 to 20:\n",
    "<div>\n",
    "<img src=\"plots/test_raw_full_nozeros.png\" width=\"400\"/>\n",
    "<img src=\"plots/test_raw_nozeros_0_20.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf41c6c",
   "metadata": {},
   "source": [
    "e) The distribution in both raw and preprocessed cases shows that there are plenty of zero values and values from zero to two. The higher the value gets, the less observations are supporting it. Biological explanation for it is that in our data we have many observations where gene expression is zero, which means there is no expression of such gene. Also, there are many observations where specific genes reach very low expression - values 0 to 5 (very low values considering the highest in raw data is 35 451 and in preprocessed data 21 078 940)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5fecf4",
   "metadata": {},
   "source": [
    "f) In adata.obs dataframe we can find columns: 'GEX_n_genes_by_counts', GEX_pct_counts_mt', 'GEX_size_factors','GEX_phase', 'ADT_n_antibodies_by_counts', 'ADT_total_counts', 'ADT_iso_count', 'cell_type', 'batch', 'ADT_pseudotime_order', 'GEX_pseudotime_order', 'Samplename', 'Site', 'DonorNumber', 'Modality', 'VendorLot', 'DonorID', 'DonorAge', 'DonorBMI', 'DonorBloodType', 'DonorRace', 'Ethnicity', 'DonorGender', 'QCMeds', 'DonorSmoker', 'is_train'.\n",
    "\n",
    "This is additional data about samples and patients that they came from.\n",
    "\n",
    "There are 45 types of cells from 9 different patients. There are 4 labs that samples came from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f64bc6a",
   "metadata": {},
   "source": [
    "### Vanilla VAE training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4b35e",
   "metadata": {},
   "source": [
    "###### Processing\n",
    "There was log1p applied on data due to problems with gradient computing.\n",
    "\n",
    "Histograms for preprocessed training data with applied log1p:\n",
    "\n",
    "<div>\n",
    "<img src=\"plots/train_pp_full_log.png\" width=\"400\"/>\n",
    "<img src=\"plots/train_pp_05_10_log.png\" width=\"400\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4426827",
   "metadata": {},
   "source": [
    "#### Vanilla VAE\n",
    "\n",
    "```python\n",
    "class Network(torch.nn.Module):\n",
    "  def __init__(self, input_dim, h_dim = 200, z_dim=20, o_dim=20):\n",
    "    super(Network, self).__init__()\n",
    "    self.img2hid = nn.Linear(input_dim, h_dim)\n",
    "    self.hid2mu_e = nn.Linear(h_dim, z_dim)\n",
    "    self.hid2sigma_e = nn.Linear(h_dim, z_dim)\n",
    "\n",
    "    self.z2hid = nn.Linear(z_dim, h_dim)\n",
    "    self.hid2mu_d = nn.Linear(h_dim, input_dim)\n",
    "    self.hid2sigma_d = nn.Linear(h_dim, input_dim)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "  def encode(self, x):\n",
    "    h = self.relu(self.img2hid(x))\n",
    "    mu, sigma = self.hid2mu_e(h), self.hid2sigma_e(h)\n",
    "    return mu, sigma\n",
    "\n",
    "  def decode(self, z):\n",
    "    h = self.relu(self.z2hid(z))\n",
    "    mu, sigma = self.hid2mu_d(h), self.hid2sigma_d(h)\n",
    "    return mu, sigma\n",
    "\n",
    "class EncoderGaussian(torch.nn.Module):\n",
    "  def __init__(self, network):\n",
    "    super(EncoderGaussian, self).__init__()\n",
    "    self.network = network\n",
    "    self.dist = None\n",
    "    self.mu = None\n",
    "    self.var = None\n",
    "    self.log_var = None\n",
    "\n",
    "  def log_prob(self,x):\n",
    "    return self.dist.log_prob(x).sum(-1)\n",
    "\n",
    "  def _sample(self):\n",
    "    return self.dist.rsample()\n",
    "  \n",
    "  def forward(self,x):\n",
    "    mu, log_var = self.network.encode(x)\n",
    "    var = torch.exp(log_var)\n",
    "    cov = torch.diag_embed(var)\n",
    "    self.dist = torch.distributions.MultivariateNormal(mu, cov)\n",
    "    self.mu = mu\n",
    "    self.log_var = log_var\n",
    "    self.var = var\n",
    "    return mu, var\n",
    "\n",
    "class DecoderGaussian(torch.nn.Module):\n",
    "  def __init__(self, network):\n",
    "    super(DecoderGaussian, self).__init__()\n",
    "    self.network = network\n",
    "    self.mu = None\n",
    "    self.var = None\n",
    "    self.dist = None\n",
    "\n",
    "  def _sample(self):\n",
    "    return torch.sigmoid(self.dist.sample()) #??sigmoud??\n",
    "\n",
    "  def log_prob(self,x):\n",
    "    return self.dist.log_prob(x).sum(-1)\n",
    "\n",
    "  def forward(self,x):\n",
    "    mu, log_var = self.network.decode(x)\n",
    "    var = torch.exp(log_var)\n",
    "    cov = torch.diag_embed(var)\n",
    "    self.dist = torch.distributions.MultivariateNormal(mu, cov)\n",
    "    self.mu = mu\n",
    "    self.var = var\n",
    "    return mu, var\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "  def __init__(self, encoder, decoder):\n",
    "    super().__init__()\n",
    "    self.encoder = encoder\n",
    "    self.decoder = decoder\n",
    "    self.prior_dist = torch.distributions.MultivariateNormal(torch.zeros([Z_DIM]).to(DEVICE), torch.eye(Z_DIM).to(DEVICE))\n",
    "\n",
    "  def loss_fn(self, x):\n",
    "    reconstruction_loss = self.decoder.log_prob(x)\n",
    "    regularization_loss = BETA*torch.sum(torch.distributions.kl.kl_divergence(self.prior_dist, self.encoder.dist))\n",
    "    elbo = reconstruction_loss - regularization_loss\n",
    "    return -elbo, reconstruction_loss, regularization_loss\n",
    "\n",
    "  def encode(self, x):\n",
    "    self.encoder.forward(x)\n",
    "    z = self.encoder._sample()\n",
    "    return z\n",
    "\n",
    "  def decode(self, z):\n",
    "    self.decoder.forward(z)\n",
    "    x_hat = self.decoder._sample()\n",
    "    return x_hat\n",
    "    \n",
    "  def forward(self,x):\n",
    "    z = self.encode(x)\n",
    "    x_hat = self.decode(z)\n",
    "    return z, x_hat\n",
    "\n",
    "class RNAseq_Dataset(Dataset):\n",
    "  def __init__(self, matrix, cell_types):\n",
    "    self.rows = [matrix[i, :] for i in range(matrix.shape[0])]\n",
    "    self.targets = list(zip(self.rows, cell_types))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    sc, ct = self.targets[index]\n",
    "    return sc, ct\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5715817",
   "metadata": {},
   "source": [
    "Due to limited time and long calculations I trained VAE only on 0.5% of the data - one epoch, batch size 10. Therefore, following plots are based on iterations, not epochs.\n",
    "\n",
    "a) Learning curves for training set and test set while training:\n",
    "\n",
    "<div>\n",
    "<img src=\"plots/TRAIN_ELBO_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "<img src=\"plots/TRAIN_REC_LOSS_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "<img src=\"plots/TRAIN_REG_LOSS_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "</div>\n",
    "<div>\n",
    "<img src=\"plots/TEST_ELBO_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "<img src=\"plots/TEST_REC_LOSS_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "<img src=\"plots/TEST_REG_LOSS_b1_epochs1_hdim300_zdim100_lr0.005_batch10.png\" width=\"300\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881116d2",
   "metadata": {},
   "source": [
    "b) Number of principal components that explain more than 95% of the variance of latent space.\n",
    "\n",
    "Model with latent space size = 50: 44 principal components\n",
    "\n",
    "Model with latent space size = 100: 85 principal components\n",
    "\n",
    "Model with latent space size = 150: 120 principal components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0249e87",
   "metadata": {},
   "source": [
    "##### ELBO for testing on models with different latent space sizes:\n",
    "\n",
    "-ELBO after last iteration of testing on model with latent space size torch.Size([1, 50]) tensor(5083.1313)\n",
    "\n",
    "-ELBO after last iteration of testing on model with latent space size torch.Size([1, 100]) tensor(4949.6885)\n",
    "\n",
    "-ELBO after last iteration of testing on model with latent space size torch.Size([1, 150]) tensor(6479.8071)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e428c56",
   "metadata": {},
   "source": [
    "Plots for PCA\n",
    "\n",
    "#### Latent space size = 50\n",
    "\n",
    "<div>\n",
    "<img src=\"/plots/PCA_test_zdim50.png\" width=\"600\"/>\n",
    "</div>\n",
    "\n",
    "#### Latent space size = 100\n",
    "\n",
    "<div>\n",
    "<img src=https://github.com/rmalinowska/SAD2/tree/master/projekt1/plots/PCA_test_zdim100.png\" width=\"600\"/>\n",
    "</div>\n",
    "![](https://github.com/rmalinowska/SAD2/tree/master/projekt1/plots/PCA_test_zdim100.png?raw=true)\\n\n",
    "#### Latent space size = 150\n",
    "\n",
    "<div>\n",
    "<img src=\"plots/PCA_test_zdim150.png\" width=\"600\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269ec046",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 22:45:29) [MSC v.1916 32 bit (Intel)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "a3899ec9cc02efd17340ce62d3092031da3cdd99c51a3380f7bed7fe1f1c368c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
